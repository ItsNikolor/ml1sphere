{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 21 октября 2019, 08:30 \n",
    "\n",
    "**Штраф за опоздание:** по 0.5 балла за 24 часа задержки. Через 10 дней домашнее задание сгорает.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "\n",
    "[ML0919, Задание 1] Фамилия Имя.\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -0.5 баллов\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw1.ipynb) -0.5 баллов\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -0.5 баллов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.datasets import fetch_mldata, fetch_20newsgroups\n",
    "\n",
    "from sklearn.neighbors.base import NeighborsBase, KNeighborsMixin, SupervisedIntegerMixin \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier,KDTree\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "\n",
    "from math import sqrt\n",
    "#%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Задание 1 (1 балл)\n",
    "Реализовать KNN в классе MyKNeighborsClassifier (обязательное условие: точность не ниже sklearn реализации)\n",
    "Разберитесь самостоятельно, какая мера расстояния используется в KNeighborsClassifier дефолтно и реализуйте свой алгоритм именно с этой мерой. Самостоятельно разберитесь, как считается score из KNeighborsClassifier и реализуйте аналог в своём классе. Score не должен уступать значению KNN из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "class MyKNeighborsClassifier(NeighborsBase, KNeighborsMixin, SupervisedIntegerMixin, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, n_neighbors, algorithm='brute'):\n",
    "        self.n_neighbors=n_neighbors\n",
    "        self.alg=(algorithm=='brute')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.y=y\n",
    "        if self.alg:\n",
    "            self.x = X if type(X)==csr_matrix else X.T[np.newaxis,...]\n",
    "           # if type(X)==csr_matrix:\n",
    "           #     self.x=X\n",
    "           # else:\n",
    "            #    self.x=X.T[np.newaxis,...]\n",
    "        else:\n",
    "            self.tree=KDTree(X, leaf_size=40)\n",
    "    \n",
    "    def predict(self, X,metric='euclidean'):\n",
    "        if self.alg:\n",
    "            if type(X)==csr_matrix:\n",
    "                dist=pairwise_distances(X,self.x,metric=metric)\n",
    "            else:\n",
    "                dist=np.sqrt(((X[...,np.newaxis]-self.x)**2).sum(axis=1))\n",
    "            tmp=np.argpartition(dist, self.n_neighbors,axis=-1)[:,:self.n_neighbors]\n",
    "        else:\n",
    "            tmp = self.tree.query(X, k=self.n_neighbors,return_distance =False)\n",
    "        tmp=self.y[tmp][...,np.newaxis]\n",
    "        labels=np.unique(self.y)[np.newaxis][np.newaxis]\n",
    "        return labels[0,0,(labels==tmp).sum(axis=1).argmax(axis=1)]\n",
    "            \n",
    "    \n",
    "    def predict_proba(self, X,metric='euclidean'):\n",
    "        if self.alg:\n",
    "            if type(X)==csr_matrix:\n",
    "                dist=pairwise_distances(X,self.x,metric=metric)\n",
    "            else:\n",
    "                dist=np.sqrt(((X[...,np.newaxis]-self.x)**2).sum(axis=1))\n",
    "            tmp=np.argpartition(dist, self.n_neighbors,axis=-1)[:,:self.n_neighbors]\n",
    "        else:  \n",
    "            tmp = self.tree.query(X, k=self.n_neighbors,return_distance =False)\n",
    "            \n",
    "        tmp=self.y[tmp][...,np.newaxis]\n",
    "        labels=np.unique(self.y)[np.newaxis][np.newaxis]\n",
    "        tmp= (labels==tmp).sum(axis=1)\n",
    "        return tmp/tmp.sum(axis=1)[:,np.newaxis]\n",
    "    \n",
    "    def score(self, X, y,metric='euclidean'):\n",
    "        return (self.predict(X,metric)==y).sum()/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IRIS**\n",
    "\n",
    "В библиотеке scikit-learn есть несколько датасетов из коробки. Один из них [Ирисы Фишера](https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='brute')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(my_clf.score(X_test, y_test) - clf.score(X_test,y_test))<0.005, \"Score must be simillar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (0.5 балла)**\n",
    "\n",
    "Давайте попробуем добиться скорости работы на fit, predict и predict_proba сравнимой со sklearn для iris.\n",
    "Для этого используем numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1e+03 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 997 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 0, 2, 0, 2, 1, 0, 1, 0, 2, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.23 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 0, 2, 0, 2, 1, 0, 1, 0, 2, 0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.43 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 970 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 3 (1 балл)\n",
    "Добавьте algorithm='kd_tree' в реализацию KNN (использовать KDTree из sklearn.neighbors). Необходимо добиться скорости работы на fit,  predict и predict_proba сравнимой со sklearn для iris.\n",
    "Для этого используем numpy. Score не должен уступать значению KNN из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='kd_tree')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='kd_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 642 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 999 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 2, 1, 1, 2, 1, 0, 0, 0, 1, 2, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 995 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 2, 1, 1, 2, 1, 0, 0, 0, 1, 2, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 500 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(my_clf.score(X_test, y_test) - clf.score(X_test,y_test))<0.005, \"Score must be simillar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (2.5 балла)**\n",
    "\n",
    "Рассмотрим новый датасет 20 newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='train',remove=['headers','footers', 'quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = newsgroups['data']\n",
    "target = newsgroups['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведите во всех документах все буквы в нижний регистр и замените во всех документах символы, не\n",
    "являющиеся буквами и цифрами, на пробелы. Далее разбейте текста по пробельным символам на токены(термы/слова). Удалите текста, содержащие только пробелы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tok=[]\n",
    "indices=[]\n",
    "for ind,line in enumerate(data):\n",
    "    line=line.lower()\n",
    "    tmp=list(line)\n",
    "    for i, c in enumerate(line):\n",
    "        if(not(c.isalpha() or c.isdigit())):\n",
    "            tmp[i]=' '\n",
    "    tmp=''.join(tmp).split()\n",
    "    if tmp:\n",
    "        data_tok.append(tmp)\n",
    "        indices.append(ind)\n",
    "target=target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(isinstance(row, (list, tuple)) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
    "assert all(all(isinstance(tok, str) for tok in row) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
    "is_latin = lambda tok: all('a' <= x.lower() <= 'z' for x in tok)\n",
    "assert all(map(lambda l: not is_latin(l) or l.islower() , map(' '.join, data_tok))), \"please make sure that you lowercase the data and drop spaced texts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте датасет в разреженную матрицу scipy.sparse.csr_matrix, где значение x в позиции (i, j)\n",
    "означает, что в документе i слово j встретилось x раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "indptr = [0]\n",
    "indices = []\n",
    "data = []\n",
    "words = {}\n",
    "for d in data_tok:\n",
    "    data+=[1]*len(d)\n",
    "    for token in d:\n",
    "        index = words.setdefault(token, len(words))\n",
    "        indices.append(index)\n",
    "    indptr.append(len(indices))\n",
    "\n",
    "sm=csr_matrix((data, indices, indptr), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Так мы получили векторное представление наших текстов. Значит можно приступать к задаче обучения модели*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте разбиение выборки для кросс-валидации на 3 фолдах. Разрешено использовать sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits=3\n",
    "kf = KFold(n_splits=n_splits,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 neighbors: 0.21301344965467103\n",
      "2 neighbors: 0.19292984369320246\n",
      "3 neighbors: 0.18784078516902944\n",
      "4 neighbors: 0.18747728098873137\n",
      "5 neighbors: 0.19074881861141404\n",
      "6 neighbors: 0.1952926208651399\n",
      "7 neighbors: 0.19783715012722647\n",
      "8 neighbors: 0.20528898582333696\n",
      "9 neighbors: 0.20083605961468556\n",
      "10 neighbors: 0.19974554707379136\n",
      "best k = 1\n"
     ]
    }
   ],
   "source": [
    "best_k=0\n",
    "best_score=-1.0\n",
    "for k in range(1,11):\n",
    "    score_sum=0\n",
    "    my_clf = MyKNeighborsClassifier(n_neighbors=k, algorithm='brute')\n",
    "    for train_indx,test_indx in kf.split(sm):\n",
    "        my_clf.fit(sm[train_indx],target[train_indx])\n",
    "        score_sum+=my_clf.score(sm[test_indx],target[test_indx])\n",
    "    if score_sum/n_splits>best_score:\n",
    "        best_score=score_sum/n_splits\n",
    "        best_k=k\n",
    "    print(k,'neighbors:',score_sum/n_splits)\n",
    "print('best k =',best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите метод, позволяющий найти оптимальное количество ближайших соседей(дающее максимальный score в среднем на валидации на 3 фолдах).\n",
    "Постройте график зависимости среднего score от количества соседей. Можно рассмотреть число соседей от 1 до 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default: 0.21628498727735368\n",
      "with cosine: 0.28789531079607417\n",
      "with tf-ifd: 0.6019629225736096\n",
      "with tf-idf and cosine: 0.6019629225736096\n"
     ]
    }
   ],
   "source": [
    "n_splits=3\n",
    "kf = KFold(n_splits=n_splits,shuffle=False)\n",
    "\n",
    "score_sum=0\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=best_k, algorithm='brute')\n",
    "for train_indx,test_indx in kf.split(sm):\n",
    "    my_clf.fit(sm[train_indx],target[train_indx])\n",
    "    score_sum+=my_clf.score(sm[test_indx],target[test_indx])\n",
    "print('default:',score_sum/n_splits)\n",
    "\n",
    "score_sum=0\n",
    "for train_indx,test_indx in kf.split(sm):\n",
    "    my_clf.fit(sm[train_indx],target[train_indx])\n",
    "    score_sum+=my_clf.score(sm[test_indx],target[test_indx],'cosine')\n",
    "print('with cosine:',score_sum/n_splits)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf=TfidfTransformer()\n",
    "tf.fit(sm)\n",
    "score_sum=0\n",
    "sm_tf=tf.transform(sm)\n",
    "\n",
    "for train_indx,test_indx in kf.split(sm_tf):\n",
    "    my_clf.fit(sm_tf[train_indx],target[train_indx])\n",
    "    score_sum+=my_clf.score(sm_tf[test_indx],target[test_indx])\n",
    "print('with tf-idf:',score_sum/n_splits)\n",
    "\n",
    "score_sum=0\n",
    "for train_indx,test_indx in kf.split(sm_tf):\n",
    "    my_clf.fit(sm_tf[train_indx],target[train_indx])\n",
    "    score_sum+=my_clf.score(sm_tf[test_indx],target[test_indx],'cosine')\n",
    "print('with tf-idf and cosine:',score_sum/n_splits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как изменится качество на валидации, если:\n",
    "\n",
    "1. Используется косинусная метрика вместо евклидовой.\n",
    "2. К текстам применяется TfIdf преобразование( sklearn.feature_extraction.text.TfidfTransformer)\n",
    "\n",
    "Сравните модели, выберите лучшую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим  теперь test  часть нашей выборки и преобразуем её аналогично с train частью. Не забудьте, что наборы слов в train и test части могут отличаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='test',remove=['headers','footers', 'quotes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество(score) вашей лучшей модели на test части датасета. Отличается ли оно от кросс-валидации? Попробуйте сделать выводы, почему отличается качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = newsgroups['data']\n",
    "target_test = newsgroups['target']\n",
    "\n",
    "data_tok=[]\n",
    "indices=[]\n",
    "for ind,line in enumerate(data_test):\n",
    "    line=line.lower()\n",
    "    tmp=list(line)\n",
    "    for i, c in enumerate(line):\n",
    "        if(not(c.isalpha() or c.isdigit())):\n",
    "            tmp[i]=' '\n",
    "    tmp=''.join(tmp).split()\n",
    "    if tmp:\n",
    "        data_tok.append(tmp)\n",
    "        indices.append(ind)\n",
    "target_test=target_test[indices]\n",
    "\n",
    "\n",
    "indptr = [0]\n",
    "indices = []\n",
    "data = []\n",
    "for d in data_tok:\n",
    "    for token in d:\n",
    "        if words.get(token,-1)==-1:\n",
    "            continue\n",
    "        index = words[token]\n",
    "        indices.append(index)\n",
    "        data.append(1)\n",
    "    indptr.append(len(indices))\n",
    "\n",
    "sm_test=csr_matrix((data, indices, indptr), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final: 0.5194965111506362\n"
     ]
    }
   ],
   "source": [
    "my_clf = MyKNeighborsClassifier(n_neighbors=best_k, algorithm='brute')\n",
    "my_clf.fit(sm_tf,target)\n",
    "score=my_clf.score(tf.transform(sm_test),target_test)\n",
    "print('Final:',score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
