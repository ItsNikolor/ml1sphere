{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKs7xC6lIvYL"
   },
   "outputs": [],
   "source": [
    "%run Pre_ini.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nwgiPweulW0b"
   },
   "outputs": [],
   "source": [
    "Document = namedtuple('Document',['description','author','keywords',\n",
    "                                  'title','body_a','body_h1',\n",
    "                                  'body_h3','body_strong',\n",
    "                                  'body_rest'])\n",
    "\n",
    "def build_dict(words):\n",
    "    counter=defaultdict(int)\n",
    "    for word in words:\n",
    "        counter[word]+=1\n",
    "    return (dict(counter),len(words))\n",
    "    \n",
    "\n",
    "def build_docs():\n",
    "    IDF_lem=defaultdict(int)\n",
    "    docs=[None]*(len(get_id)+1)\n",
    "    docs[0]=(dict(),Document(*[0]*9))\n",
    "\n",
    "    i=0\n",
    "    with ZipFile('all_docs_lem.zip') as myzip:\n",
    "        files=myzip.namelist()\n",
    "        with myzip.open(files[0]) as f:\n",
    "            for line in f:\n",
    "                words=line.decode('utf-8').rstrip('\\n').split('\\t')\n",
    "                doc_id=int(words[0])\n",
    "\n",
    "\n",
    "\n",
    "                words_description=words[1].split()\n",
    "\n",
    "                words_author=words[2].split()\n",
    "\n",
    "                words_keywords=words[3].split()\n",
    "\n",
    "                words_title=words[4].split()\n",
    "\n",
    "                words_a=words[5].split()\n",
    "                words_h1=words[6].split()\n",
    "                words_h3=words[7].split()\n",
    "                words_strong=words[8].split()\n",
    "                words_rest=words[9].split()\n",
    "\n",
    "\n",
    "                all_words=set()\n",
    "                feature=defaultdict(lambda:[0]*9)\n",
    "                lens=[0]*9\n",
    "\n",
    "                for ind,words in enumerate(\n",
    "                    [words_description,\n",
    "                    words_author,\n",
    "                    words_keywords,\n",
    "                    words_title,\n",
    "                    words_a,\n",
    "                    words_h1,\n",
    "                    words_h3,\n",
    "                    words_strong,\n",
    "                    words_rest\n",
    "                     ]):\n",
    "                    for word in words:\n",
    "                        feature[word][ind]+=1\n",
    "                        all_words.add(word)\n",
    "                    lens[ind]+=len(words)\n",
    "\n",
    "\n",
    "                for word in all_words:\n",
    "                    IDF_lem[word]+=1\n",
    "\n",
    "                opt_feature=dict()\n",
    "                for key in feature:\n",
    "                    opt_feature[key]=Document(*feature[key])\n",
    "\n",
    "                docs[doc_id]=(opt_feature,Document(*lens))\n",
    "\n",
    "                i+=1\n",
    "                if i%500==0:\n",
    "                    print(i)\n",
    "                \n",
    "    return (docs,IDF_lem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIjv7D8yoJZI"
   },
   "outputs": [],
   "source": [
    "docs,IDF_lem=build_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HTX4QmZu-ej"
   },
   "outputs": [],
   "source": [
    "def RIDF(word,N,R,k,l):\n",
    "    n=IDF_lem[word]\n",
    "    if R:\n",
    "        r=r_counter[word]\n",
    "        ans=log(1+(r+k)*(N-n-R+r+k)/(n-r+k)/(R-r+k))\n",
    "        if ans<=0:\n",
    "            print(word,N,n,R,r)\n",
    "            return 0\n",
    "        else:\n",
    "            return ans\n",
    "    else:\n",
    "        return log(l+(N-n)/n)\n",
    "\n",
    "def build_avl(v):\n",
    "    avl=0\n",
    "    for doc in docs[1:]:\n",
    "        avl+=sum(map(lambda x,y:x*y,doc[1],v))\n",
    "    return avl/len(get_id)\n",
    "\n",
    "def BM25F(query,doc_id,v,avl,R,k1,b,k,l,w_query):\n",
    "    score=0\n",
    "    doc=docs[doc_id]\n",
    "    dl=sum(map(lambda x,y:x*y,doc[1],v))\n",
    "    for word in query:\n",
    "        if word in doc[0]:\n",
    "            f=sum(map(lambda x,y:x*y,doc[0][word],v))\n",
    "            score+=w_query[word]*(RIDF(word,len(get_id),R,k,l)*\n",
    "                    (k1+1)*f/(k1*(1-b+b*dl/avl)+f))\n",
    "\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dLZRw6uq8Rz2"
   },
   "outputs": [],
   "source": [
    "candidates,_=generate_candidates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "KEIEGEPuNU2b",
    "outputId": "71598641-a9f6-43ec-8cc8-edb14c66f2e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(description=5, author=11, keywords=3, title=7, body_a=1, body_h1=1, body_h3=1, body_strong=1, body_rest=1)"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document(5,11,3,7,  1,1,1,1,1) #0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PwaA000jqLnK"
   },
   "outputs": [],
   "source": [
    "'''R=10\n",
    "relevance=defaultdict(list)\n",
    "with open('best.txt','r') as f:\n",
    "    f.readline()\n",
    "    for _ in range(399):\n",
    "        for i in range(R):\n",
    "            query_id,doc_id=list(map(int,f.readline().strip().split(',')))\n",
    "            relevance[query_id].append(doc_id)\n",
    "        for i in range(10-R):\n",
    "            f.readline()\n",
    "relevance[1]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKme2Cc5SwAU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPBMQnDhSw1h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "AgxqOTRyS6RD",
    "outputId": "3d3b8269-7572-486a-82c6-d9af120202dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the model...\n"
     ]
    }
   ],
   "source": [
    "%run Rus_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TaDiENdtS-ON"
   },
   "outputs": [],
   "source": [
    "process(process_pipeline, text=\"Это какой-то текст. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RRiA6qt7UUSp"
   },
   "outputs": [],
   "source": [
    "def extend(query_id,top_n):\n",
    "    true_query_pos=process(process_pipeline, text=get_query[query_id])\n",
    "    true_query=set(map(lambda x: x.split('_')[0],true_query_pos))\n",
    "    ans=set()\n",
    "    for word in true_query_pos:\n",
    "        if word in model_word.vocab:\n",
    "            for ext_word in model_word.most_similar(positive=[word])[:top_n]:\n",
    "                if ext_word[1]<0.6:\n",
    "                    continue\n",
    "                ext_word=''.join(process_string(ext_word[0].split('_')[0]).split())\n",
    "                ext_word=add_cash(ext_word)\n",
    "                if ext_word not in true_query:\n",
    "                    ans.add(ext_word)\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "ud3eB59kEiHs",
    "outputId": "cd54bea2-a626-4ccb-c94a-cb3a739681ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "v=Document(4,12,8,10,  1,7,4,1,1) \n",
    "\n",
    "w_syn=0.2\n",
    "top_syn=3\n",
    "\n",
    "R=10\n",
    "m=7\n",
    "w_pseudo=0.35\n",
    "\n",
    "k1=1.2\n",
    "b=0.75\n",
    "\n",
    "k=0.5\n",
    "l=2\n",
    "\n",
    "\n",
    "avl=build_avl(v)\n",
    "best_n=10\n",
    "\n",
    "query_ext=dict()\n",
    "with open('queries.fixed.txt') as f:\n",
    "    with open('BM25.txt','w') as out:         \n",
    "        for i,line in enumerate(f):\n",
    "            query_id,raw_query=line.split('\\t')\n",
    "            query=string_lem(raw_query.strip()).split()\n",
    "            #true_query=set(query)\n",
    "            w_query={word:1 for word in query}\n",
    "            syn_query=extend(int(query_id),top_syn)\n",
    "            for word in syn_query:\n",
    "                w_query[word]=w_syn\n",
    "                query.append(word)\n",
    "            \n",
    "\n",
    "            heap=[(-1,0)]*R\n",
    "\n",
    "            for cand in candidates[int(query_id)]:\n",
    "                heapq.heappushpop(heap,(BM25F(query,cand,v,avl,0,k1,b,k,l,w_query),cand))\n",
    "\n",
    "            scores=sorted(heap,key=lambda x:-x[0])\n",
    "            r_counter=defaultdict(int)\n",
    "\n",
    "            for _,doc_id in scores:\n",
    "                for word in docs[doc_id][0]:\n",
    "                    r_counter[word]+=1\n",
    "\n",
    "            '''r_counter=defaultdict(int)\n",
    "            for doc_id in relevance[int(query_id)]:\n",
    "                for word in docs[doc_id][0]:\n",
    "                    r_counter[word]+=1'''\n",
    "\n",
    "            heap=[(-1,'')]*50\n",
    "            for word in r_counter:\n",
    "                if r_counter[word]>1:\n",
    "                    heapq.heappushpop(heap,(log(r_counter[word])*RIDF(word,len(get_id),R,k,l),word))\n",
    "\n",
    "\n",
    "            \n",
    "            scores=sorted(heap,key=lambda x:-x[0])\n",
    "            query_ext[int(query_id)]=scores\n",
    "            scores=scores[:m]\n",
    "            #print('before=',query)\n",
    "            \n",
    "            \n",
    "            for score,word in scores:\n",
    "                if word not in query:\n",
    "                    query.append(word)\n",
    "                    w_query[word]=w_pseudo\n",
    "\n",
    "            \n",
    "            #print('after=',query)\n",
    "        \n",
    "            out.write(query_id+'\\t')\n",
    "            for cand in candidates[int(query_id)]:\n",
    "                score,doc_id=(BM25F(query,cand,v,avl,R,k1,b,k,l,w_query),cand)\n",
    "                out.write(str(score)+','+str(doc_id))\n",
    "                out.write(' ')\n",
    "            out.write('\\n')\n",
    "\n",
    "            \n",
    "            if i%100==0:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9N-Ym8ooRWzS"
   },
   "outputs": [],
   "source": [
    "with open('super_query_ext.pickle','wb') as out:\n",
    "    pickle.dump(query_ext,out)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Text relevance BM25F.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
